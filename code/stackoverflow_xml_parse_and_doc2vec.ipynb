{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from xml.etree.ElementTree import iterparse\n",
    "from lxml import html\n",
    "\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "\n",
    "import string\n",
    "import logging\n",
    "import simplejson\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                    level=logging.INFO,\n",
    "                    filename='../log/w2v_etc.log')\n",
    "\n",
    "log = logging.getLogger('w2v_etc.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Streaming xml parser filters on date and writes to csv \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#SOURCE_PATH = '../datasets/buddhism/Posts.xml'\n",
    "#SECONDARY_PATH = '../output/stackoverflow_posts.csv'\n",
    "\n",
    "SOURCE_PATH = '../datasets/stackoverflow_posts.xml'\n",
    "SECONDARY_PATH = '../datasets/stackoverflow_posts.csv'\n",
    "\n",
    "START_DATE = '2015-03-01'\n",
    "STOP_DATE = '2015-09-01'\n",
    "\n",
    "\n",
    "def _paragraph_generator(elem):\n",
    "    \n",
    "    def _assess_date_get_body():\n",
    "        date = elem.get('CreationDate', '')\n",
    "        body = elem.get('Body', '')\n",
    "        if not date or not body or date < START_DATE or date >= STOP_DATE:\n",
    "            return ''\n",
    "        else:\n",
    "            return body\n",
    "    \n",
    "    body = _assess_date_get_body()\n",
    "    if body:\n",
    "\n",
    "        def _gather_context_tag(tag, prefix):\n",
    "            x = elem.get(tag, '')\n",
    "            if x: x = prefix + '_' + x\n",
    "            return x\n",
    "\n",
    "        def _gather_context_tags():\n",
    "            owner_user = _gather_context_tag('OwnerUserId', 'OWNER')\n",
    "            post_type = _gather_context_tag('PostTypeId', 'TYPE')\n",
    "            parent = _gather_context_tag('ParentId', 'PARENT')\n",
    "            post = _gather_context_tag('Id', 'POST')\n",
    "            tags = [owner_user, post_type, parent, post]\n",
    "            return [t for t in tags if t]\n",
    "\n",
    "        def _format_stackoverflow_tags(tags):\n",
    "            tree = html.fromstring(tags)\n",
    "            tags = ['TAG_' + t.tag for t in tree.xpath('//*')]\n",
    "            return [t for t in tags if t]\n",
    "\n",
    "        def _gather_stackoverflow_tags():\n",
    "            tags = elem.get('Tags', [])\n",
    "            if tags: tags = _format_stackoverflow_tags(tags)\n",
    "            return [t for t in tags if t]\n",
    "\n",
    "        def _gather_doc2vec_tags():\n",
    "            return _gather_stackoverflow_tags() + _gather_context_tags()\n",
    "\n",
    "        tags = _gather_doc2vec_tags()\n",
    "\n",
    "        def _prepare_words(paragraph):\n",
    "            p = paragraph\n",
    "            p = p.translate(p.maketrans(\"\",\"\", string.punctuation))\n",
    "            p = p.translate(p.maketrans(\"   \",\"   \", '\\n\\t'))\n",
    "            p = p.lower()\n",
    "            return [w for w in p.split(' ') if w]\n",
    "        \n",
    "        def _gather_paragraphs():\n",
    "            body_tree = html.fromstring(body)\n",
    "            return [p.text for p in body_tree.xpath('//p') if p.text]\n",
    "        \n",
    "        paragraphs = _gather_paragraphs()\n",
    "        \n",
    "        for p in paragraphs:\n",
    "            words = _prepare_words(p)\n",
    "            yield words, tags\n",
    "\n",
    "            \n",
    "def _write_paragraphs(paragraphs, file):\n",
    "    n = 0\n",
    "    for words, tags in paragraphs:\n",
    "        n += 1\n",
    "        file.write(','.join(words))\n",
    "        file.write(';')\n",
    "        file.write(','.join(tags))\n",
    "        file.write('\\n')\n",
    "    return n\n",
    "\n",
    "\n",
    "def write_secondary():\n",
    "    n_elem = 0\n",
    "    n_para = 0\n",
    "    try:\n",
    "        file = open(SECONDARY_PATH, 'w+')\n",
    "        for event, elem in iterparse(SOURCE_PATH):\n",
    "            n_elem += 1\n",
    "            if (n_elem % 100000 == 0): log.info(str(n_para) + ' ' + str(n_elem))\n",
    "            try:\n",
    "                paragraphs = _paragraph_generator(elem)\n",
    "                n_para += _write_paragraphs(paragraphs, file)\n",
    "            except Exception as e:\n",
    "                log.warning((type(e), e))\n",
    "            finally:\n",
    "                elem.clear()\n",
    "    finally:\n",
    "        file.close()\n",
    "\n",
    "\n",
    "write_secondary()\n",
    "\n",
    "\n",
    "class SecondaryReader():\n",
    "    def __init__(self): pass\n",
    "    def __iter__(self):\n",
    "        with open(SECONDARY_PATH, 'r') as file:\n",
    "            for line in file:\n",
    "                line = line[:-1]\n",
    "                words, tags = line.split(';')[0:2]\n",
    "                words = words.split(',')\n",
    "                tags = tags.split(',')\n",
    "                return words, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class StackOverflowPostIterator:\n",
    "    def __init__(self): pass\n",
    "    def __iter__(self):\n",
    "        return SecondaryReader().__iter__()\n",
    "\n",
    "SAVE_PATH = '../saved/180_5_5_a.d2v'\n",
    "        \n",
    "def train_and_save():\n",
    "    model = Doc2Vec(StackOverflowPostIterator(),\n",
    "                    workers=5,\n",
    "                    size=180, negative=5, window=5,\n",
    "                    iter=1, alpha=0.1, sample=1e-5,\n",
    "                    min_count=1)\n",
    "    model.save(SAVE_PATH)\n",
    "    return model\n",
    "\n",
    "\n",
    "# model = train_and_save()\n",
    "model = Doc2Vec.load(SAVE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('scrum', 0.7025855779647827),\n",
       " ('testdriven', 0.5772689580917358),\n",
       " ('nameusage', 0.5521855354309082),\n",
       " ('prototyping', 0.5441562533378601),\n",
       " ('career', 0.5345290303230286),\n",
       " ('manufacturing', 0.5328176021575928),\n",
       " ('tdd', 0.5307821035385132),\n",
       " ('disciplines', 0.5286736488342285),\n",
       " ('vetting', 0.5281956195831299),\n",
       " ('collaborative', 0.5237389206886292)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('agile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "\n",
    "for sentence in StackOverflowPostIterator():\n",
    "    x = sentence\n",
    "    n -= 1\n",
    "    if (n < 0):\n",
    "        break\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "SOURCE_PATH = '../datasets/stackoverflow_posts.xml'\n",
    "\n",
    "n = 0\n",
    "m = 0\n",
    "keys = set([])\n",
    "min_date = None\n",
    "max_date = None\n",
    "start_time = datetime.now()\n",
    "\n",
    "for event, elem in iterparse(SOURCE_PATH):\n",
    "    n += 1\n",
    "    keys.update(elem.keys())\n",
    "    date = elem.get('CreationDate', '')\n",
    "    body = elem.get('Body', '')\n",
    "    elem.clear()\n",
    "    if min_date is None or (date and date < min_date): min_date = date\n",
    "    if max_date is None or (date and date > max_date): max_date = date\n",
    "    if date and body and date >= '2015-01-01' and date < '2016-01-01': m += 1\n",
    "    if (n % 1000000 == 0): print(m, n, min_date, max_date, keys)\n",
    "\n",
    "end_time = datetime.now()\n",
    "\n",
    "print(n, (end_time - start_time).total_seconds())\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
